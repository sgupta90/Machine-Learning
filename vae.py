# -*- coding: utf-8 -*-
"""hw5_vae.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1U0u-rhuctI3TsaoRAn3CA1R5yRRxjuR6
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
import numpy as np
import matplotlib.pyplot as plt

transform = transforms.Compose([transforms.ToTensor()]) # converting image to tensor between [0,1]
trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)
testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)

'''
VAE Network
'''
class VAE(nn.Module):
  def __init__(self):
    super(VAE, self).__init__()
    self.fc1 = nn.Linear(784, 400)
    self.fc21 = nn.Linear(400, 20)
    self.fc22 = nn.Linear(400, 20)
    self.fc3 = nn.Linear(20, 400)
    self.fc4 = nn.Linear(400, 784)

  def encode(self, x):
    h1 = F.relu(self.fc1(x))
    return self.fc21(h1), self.fc22(h1)

  def reparameterize(self, mu, std):
      eps = torch.randn_like(std)
      return mu + eps*std

  def decode(self, z):
      h3 = F.relu(self.fc3(z))
      return F.sigmoid(self.fc4(h3))

  def forward(self, x):
    mu, std = self.encode(x.view(-1, 784))
    z = self.reparameterize(mu, std)
    return self.decode(z), mu, std

batch = 64 #batch size
trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch, shuffle=True)
testloader = torch.utils.data.DataLoader(testset, batch_size=batch, shuffle=False)

# instantiating the model
vae = VAE()
criterion = nn.BCELoss(reduction='sum')
optimizer = optim.Adam(vae.parameters(), lr=0.001)

n = trainset.data.shape[0] #number of samples in test data
num_batch = trainset.data.shape[0]/batch #number of batches
lambd = -1 #hyperparamter for KL divergence

train_loss_list = [] # list to store training loss for each epoch

for epoch in range(epochs):
  train_loss = 0.0 # training loss in one epoch
  for batch_index, data in enumerate(trainloader, 0):
      # get the inputs; data is a list of [inputs, labels]
      x, labels = data

      #Training VAE
      # zero the parameter gradients
      optimizer.zero_grad()
     
      x_hat, mu, std = vae(x)

      #Calculating loss
      vae_loss = criterion(x_hat, x.view(-1, 784)) + lambd * 0.5 * torch.sum(1 + torch.log(std.pow(2)) - mu.pow(2) - std.pow(2))
      vae_loss.backward()
      optimizer.step()

      train_loss += vae_loss.item()
     
  train_avg_loss = train_loss/n

  print(f'epoch={epoch+1}, train_avg_loss:{train_avg_loss}')
  train_loss_list.append(train_avg_loss)

print('Finished Training')
VAE_PATH = './hw5_vae.pth'
torch.save(vae.state_dict(), VAE_PATH)

x = list(range(1, epochs+1))
plt.figure()
plt.ylabel('loss')
plt.xlabel('epoch')
plt.plot(x, train_loss_list, label='VAE loss')
plt.legend()

#Running network in test mode to get reconstructed images
vae.eval()
vae_test = VAE()
vae_test.load_state_dict(torch.load(VAE_PATH))
itr = iter(testloader)
x,_ = next(itr)
with torch.no_grad():
  x_hat, _, _ = vae_test(x)
  x_hat = x_hat.view(batch, 1, 28, 28)
  x_hat = x_hat.detach().numpy()
  fig, axes = plt.subplots(nrows=4, ncols=4, sharex=True, sharey=True, figsize=(8,8))

  #Reconstructed Images
  for imgs, row in zip([x_hat[:4], x_hat[4:8], x_hat[8:12], x_hat[12:16]], axes):
    for img, ax in zip(imgs, row):
      ax.imshow(np.squeeze(img), cmap='gray')
  plt.show()