# -*- coding: utf-8 -*-
"""hw5_gan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tywmy425_TtZdU5agpCdoY2JDmTtj-Z_
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
import numpy as np
import matplotlib.pyplot as plt

transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,),(0.5,))]) # converting image to tensor between [0,1]
trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)
testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)

'''
Generator network
'''
class Generator(nn.Module):
  def __init__(self):
    super(Generator, self).__init__()
    self.fc1 = nn.Linear(128, 256)
    self.fc2 = nn.Linear(256, 512)
    self.fc3 = nn.Linear(512, 784)

  def forward(self, x):
    x = x.view(-1, 128)
    x = F.leaky_relu(self.fc1(x), 0.2)
    x = F.leaky_relu(self.fc2(x), 0.2)
    x = F.tanh(self.fc3(x))
    return x

'''
Discriminator network
'''
class Discriminator(nn.Module):
  def __init__(self):
    super(Discriminator, self).__init__()
    self.fc1 = nn.Linear(784, 512)
    self.fc2 = nn.Linear(512, 256)
    self.fc3 = nn.Linear(256, 1)

  def forward(self, x):
    x = x.view(-1, 784)
    x = F.leaky_relu(self.fc1(x), 0.2)
    x = F.leaky_relu(self.fc2(x), 0.2)
    x = F.sigmoid(self.fc3(x))
    return x

'''
This function rescales image between 0-255
'''
def scale_image(image):
  scaled_img = image - torch.min(image).item()
  scaled_img = 255 * scaled_img/torch.max(scaled_img).item()
  scaled_img = scaled_img.view(-1, 28, 28)
  print(f'image:{image.shape} scaled_img:{scaled_img.shape}')
  return scaled_img

batch = 100 #batch size
trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch, shuffle=True)
testloader = torch.utils.data.DataLoader(testset, batch_size=batch, shuffle=False)

# instantiating the model
generator = Generator()
discriminator = Discriminator()

gen_criterion = nn.BCELoss() # setting the loss function for gen
dis_criterion = nn.BCELoss() # setting the loss function for discriminator

gen_optimizer = optim.Adam(generator.parameters(), lr=0.0002)
dis_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002)

n = trainset.data.shape[0] #number of samples in test data
num_batch = trainset.data.shape[0]/batch
epochs = 50

gen_loss_list = []
dis_loss_list = []

for epoch in range(epochs):
  gen_loss = 0.0
  dis_loss = 0.0
  for i, data in enumerate(trainloader, 0):
      # get the inputs; data is a list of [inputs, labels]
      inputs_real, labels = data
      input_gen = torch.randn(100, 128)

      #Training discriminator
      # zero the parameter gradients
      gen_optimizer.zero_grad()
      dis_optimizer.zero_grad()
      gen_output = generator(input_gen).detach()
      dis_output_fake = discriminator(gen_output)   # For Fake data
      dis_output_real = discriminator(inputs_real)  # For Real data

      #Calculating loss
      dis_loss = dis_criterion(dis_output_real, torch.ones_like(dis_output_real))  + dis_criterion(dis_output_fake, torch.zeros_like(dis_output_fake))
      dis_loss.backward()
      dis_optimizer.step()
      dis_loss += dis_loss.item()


      #Training Generator
      gen_image = generator(input_gen)
      gen_output_train = discriminator(gen_image)
      # Doing gradient ascent for fast training 
      gen_loss = gen_criterion(gen_output_train, torch.ones_like(gen_output_train))
      gen_loss.backward()
      gen_optimizer.step()
      dis_loss += gen_loss.item()
     

  gen_avg_loss = gen_loss/num_batch
  dis_avg_loss = dis_loss/num_batch

  print(f'epoch={epoch+1}, gen_avg_loss:{gen_avg_loss} dis_avg_loss:{dis_avg_loss}')
  gen_loss_list.append(gen_avg_loss)
  dis_loss_list.append(dis_avg_loss)

  if epoch%10 == 9:
    images = scale_image(gen_image.detach()[:16])
    fig, axes = plt.subplots(nrows= 4, ncols= 4, sharex= True, sharey= True, figsize=(8,8))
    for imgs, row in zip([images[:4], images[4:8], images[8:12], images[12:16]], axes):
      for img, axis in zip(imgs, row):
        axis.imshow(img, cmap = 'gray')
    plt.show()

print('Finished Training')
GEN_PATH = './hw5_gan_gen.pth'
DIS_PATH = './hw5_gan_dis.pth'
torch.save(generator.state_dict(), GEN_PATH)
torch.save(discriminator.state_dict(), DIS_PATH)

x = list(range(1, epochs+1))
plt.figure()
plt.ylabel('loss')
plt.xlabel('epoch')
plt.plot(x, gen_loss_list, label='generator loss')
plt.legend()

plt.figure()
plt.ylabel('loss')
plt.xlabel('epoch')
plt.plot(x, dis_loss_list, label='discriminator loss')
plt.legend()